[
  {
    "objectID": "chapter-1.html",
    "href": "chapter-1.html",
    "title": "Getting started",
    "section": "",
    "text": "You will need a Google account to use the notebooks, which are on Google Colab. You can set on up Set up new Google account.\nThis does not have to be your personal account, you can set one up just for data analysis, if you like.\nIf you already have one, feel free to skip ahead to Chapter 2."
  },
  {
    "objectID": "chapter-2.html",
    "href": "chapter-2.html",
    "title": "Source material",
    "section": "",
    "text": "PDF files work best for this analysis, but there are three types of PDF files to be aware of:\n\ndigitally-created pdfs such as from print streams in Word, that contain text and font-family information, and are searchable.\nscanned/image-only pdfs that contain no text information\nsearchable pdfs - where there is a text layer that has been developed with OCR and sits underneath the scanned image\n\nArchives will typically use scanned image-only pdfs, though sometimes these are saved as PDF/A, which is a reduced file size with reduced functionality. For our Gazette project, you can find high quality scans of documents here at the Dalhousie Gazette Archives. You can find the current Gazette here.\n\nThe following is an example screenshot of a multi-page scanned image PDF file of a 1922 Dalhousie Gazette.\n\n\n\nYou can also use other source materials as you get comfortable with this process. Some examples include:\n\nimages of texts taken with your smartphone.\n\n\n\n\nThe OCR notebook we provide uses PyTesseract, which is a Python wrapper for Google’s Tesseract OCR library. It is not intended for analyzing handwritting. This article on medium.com illustrates some of the challenges. For analysis of handwriting, you will want Human Handwritten Text Recognition (HTR). For those with Python experience and time to create training datasets, you can find more here."
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "license",
    "section": "",
    "text": "CC BY: This license allows reusers to distribute, remix, adapt, and build upon the material in any medium or format, so long as attribution is given to the creator. The license allows for commercial use.\n\n\n\n\ncc by logo\n\n\nCC BY includes the following elements:\nBY – Credit must be given to the creator"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "",
    "text": "Welcome to our documentation introducing you to Python-based digital humanities tools."
  },
  {
    "objectID": "index.html#what-is-digital-humanities",
    "href": "index.html#what-is-digital-humanities",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "What is Digital Humanities?",
    "text": "What is Digital Humanities?\nDigital Humanities (DH) is the application of digital tools to process information to enable researchers to explore subjects in the humanities in new ways. Digital tools can provide advantages to the researcher with processing capabilities on huge amounts of information on texts, images, sound, or even on data itself. While DH employs digital technology with the goal is deriving new insights, these same tools can also be the subject of critical inquiry as well. It is a huge field with simultaneous developments in other fields. The Wikipedia entry on DH is well worth reading for an introduction, as are the resources from University of Victoria, Stanford, and the University of California Berkeley.\nOur workshop will focus on text analysis in which we look for topics, though there are many types of text analysis."
  },
  {
    "objectID": "index.html#this-documentation-covers-the-following",
    "href": "index.html#this-documentation-covers-the-following",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "This documentation covers the following:",
    "text": "This documentation covers the following:\n\nChapter 1 - Getting started\nChapter 2 - Finding source material\nChapter 3 - Using the OCR notebook\nChapter 4 - Using the LDA notebook\nChapter 5 - Moving on and using your own data"
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "Objectives",
    "text": "Objectives\nOur workshop seeks to provide the following for our participants: \n\nUse Python to run an Optical Character Recognition (OCR) library called PyTesseract to extract text from a scanned PDF file and perform topic modeling using LDA to derive meaningful topics.\nCreate visualizations, with both Python and Tableau Public, to generate meaningful topics from the text.\nDescribe basic elements of Python, Google Colab and Tableau Public.\nCover the basics of Jupyter Notebooks hosted in the Google Colab environment.\nExplore the basic principles and limitations of topic modeling.\nDiscuss open source software and publicly available information can be implemented in social sciences and humanities research.\nUse Tableau Public to explore and analyze data using no coding, but able to produce visualizations and tables.\nCover the process to create topics from a sample covering 100 years of the Dalhousie Gazette."
  },
  {
    "objectID": "index.html#what-is-ocr",
    "href": "index.html#what-is-ocr",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "What is OCR?",
    "text": "What is OCR?\n\nOCR is Optical Character Recognition is a means of converting scanned or an image of text into searchable text that can be used for analysis. OCR has wide applications in text-to-speech, text mining and natural language processing, translation, and computer vision.\nOCR has a long history as far back as the early 1900’s, when text was optically converted into tones as an assistive technology. Today, mobile applications come with every smartphone enabling translation of signs across many languages. Google Books and Project Gutenberg are other examples of scanned image to text OCR processing.\nOur version of OCR is a Python wrapper for Google’s Tesseract which has advantages on unusual fonts or poor quality scans.\nThe input for our Python library, Pytesseract, uses PDF files. There are three types of PDF files:\n\ndigitally-created pdfs such as from print streams in Word, that contain text and font-family information, and are searchable.\nscanned/image-only pdfs that contain no text information\nsearchable pdfs - where there is a text layer that has been developed with OCR and sits underneath the scanned image\n\nAs there can be challenges with pdfs, Pytesseract will first convert all of them to images regardless of their type, process the characters using neural networks, and output the files as a plain text stream. We will then use the text files for further analysis using LDA topic modeling."
  },
  {
    "objectID": "index.html#what-is-lda",
    "href": "index.html#what-is-lda",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "What is LDA?",
    "text": "What is LDA?\n\nLDA, Latent Dirichlet Allocation, is a probability-based natural language processing (NLP) algorithm, that is specifically used to identify unknown topics within a text. While not the current state of the art, it is robust and still works pretty well!\nOur LDA notebook uses the Gensim LDA model which establishes document similarity. You can see the Gensim documentation here.\nLDA is one of a growing number of topic modelling methods used for information retrieval, enabling linked data and semantic web searching. For digital humanities researchers, we can identify topics across groups of documents, or establish document similarity, though it still relies upon the expertise of the observer to interpret ambiguous or contextual specific terms.\nWhile the notebook does have a coherence test included for validating the chosen number of topics, DH researchers should still rely upon manually validating the results.\n\nReady? Move on to Chapter 2, Getting Started."
  },
  {
    "objectID": "chapter-4.html",
    "href": "chapter-4.html",
    "title": "The LDA notebook",
    "section": "",
    "text": "You can find the LDA notebook here on GitHub.\n\n\nGoogle Colab is a Jupyter Notebook that runs on Google’s servers, allowing you to run Python code on data calculated and stored on cloud servers. This is great for large, computationally heavy projects where processing can be increased easily with a few lines of code. Unlike Jupyter notebooks run locally on your computer, the Colab environment is independent of your locally installed environments, meaning that you are less likely to run into conflicts. The downside to the Google Colab environment is that any information created in Colab is erased when you close the browser, unless you save it somewhere, like GitHub or locally on your computer.\n\n\n\n\n\nThere are two ways to open the LDA notebook:\n\nopen through Github - you will use this process the first time opening the notebooks. Look for the ‘open in Colab’ button.\n\nSave a copy of this notebook to your Google Drive. All changes will be saved to your own copy.\n\n\n\n\nOpen through Colab - You can use this process if you have previously saved it to your Google Drive.\n\nIn Colab, go to File>Open. This will open a dialog box.\nAt the top tabs of the dialog box, select Google Drive - you should see your previously saved copy.\n\n\n\nRun the first cell - this will connect to your Google Drive. A dialog box will open and ask you to select your Google account and ask for your permission to connect to your Google Drive.\nIt will also create a new directory in your Google Drive for all of the files needed for this project. You should see something like this indicating your new working directory.\n\nRun the cell that connects Colab to your drive. This gives permissions for information to be shared between the two and provides a safe place to store the results of your analysis.\n\nYour working directory is now set as folders on your Google Drive. All files saved here will be safe and not deleted when you close the notebook.\n\n\n\nInstall the libraries and dependencies needed for this notebook.\nThis cell also installs the spaCy model that is used to train the algorithm. There are different models as well as a wide range of language support. You can read more about them here.\n\n\n\nImport your data. Remember all those text files you created using the OCR notebook? Before running the cell in Step 3, move all your .txt files to the working directory in your Google Drive. You can drag them from your file manager (Finder in Mac, Explorer in Win) directly into the Colab file manager on the left.\n\n\n\n\nSet the number of n-grams. These are word combinations that are particular to your text. As an example, 2-grams, or bigrams, are word combinations like ‘Dalhousie University’ or ‘roller skate’. If they are separated, then contextual meaning can be lost. Whole phrases can be maintained this way, though specific phrases can be preserived at a later step.\nYou can adjust the n-grams at the code marked number_of_n=3. In this case, word combinations up to trigrams are preserved.\nAllowing unigrams (singular words) can also be permitted. However, these can dominate due to their increased frequency and should be tried to see if if improves your results. Look for the code include_unigrams=False and change False to True if you wish to include unigrams.\n\n\n\n\nStep 5 cleans the data by removing unneccesary words, punctuations, and symbols. You can also preserve certain phrases or words if they are important to you. Look for the code author_assigned_keywords =` and type each phrase or word you want inside double quotes, separating each with commas.\n\nCompleting step 5 will have created tokens and placed each documents tokens in a table along with the file name, document year, and content for further analysis.\n\n\n\nThis cell runs several processes we should be aware of.\n\nIt applies a filter against the dictionary to reduce extremes. With small corpora, we need to turn this off as you can see with the # before the line #dictionary.filter_extremes(no_below=5, no_above=0.2, keep_n=1000). If you are using a large corpus, then remove the # to make this line functional again.\nIt runs the LDA analysis with settings that can be adjusted, such as num_topics=5. In this case, 5 topics has already been specified. You can increase or decrease as you need.\n\nIt creates the pyLDAvis interactive webpage or results. This will be deposited in your working directory.\n\n\n\n\nThe final step in our process creates additional output from the analysis that may be useful for information retrieval or other analysis.\n\nThe number of topics are printed along with their score.\nThe topics and top 10 words/phrases are printed. You can cut and paste these into Excel or a table in a document for reporting.\nA Pandas table is created with the cluster and score next to each document, (since this was a document level clustering analysis). The table is exported as a .csv and saved in your working directory.\n\n\n\n\nThat is the final step in the analysis! You may want to move the filles you used for the analysis and the results into another folder if you’d like to analyze another batch. Simply move them, and put more .txt files into the working directory and you can repeat the notebook from Step 3.\n\n\n\nThere is a testing option for evaluating the number of topics. This works best on large corpora compared with small ones. The coherence scores were a conventional way to evaluate topic analysis, but it is beginning to fall out of favor with newer methods.\nYou can read more about coherence here and here (though this is an ad-heavy website, but the explanation is helpful).\nThe graph is read as coherence closer to 0 is better.\n\n\n\n\n\nimprove the pyLDAvis to show file names as a mouseover or separate table.\nexplain more of the tuning parameters to LDA.\nEvaluate unsupervised models versus trained models"
  }
]