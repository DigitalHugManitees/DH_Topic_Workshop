[
  {
    "objectID": "chapter-4.html",
    "href": "chapter-4.html",
    "title": "The LDA notebook",
    "section": "",
    "text": "You can find the LDA notebook here on GitHub.\n\n\nGoogle Colab is a Jupyter Notebook that runs on Google’s servers, allowing you to run Python code on data calculated and stored on cloud servers. This is great for large, computationally heavy projects where processing can be increased easily with a few lines of code. Unlike Jupyter notebooks run locally on your computer, the Colab environment is independent of your locally installed environments, meaning that you are less likely to run into conflicts. The downside to the Google Colab environment is that any information created in Colab is erased when you close the browser, unless you save it somewhere, like GitHub or locally on your computer.\n\n\n\n\n\nThere are two ways to open the LDA notebook:\n\nopen through Github - you will use this process the first time opening the notebooks. Look for the ‘open in Colab’ button.\n\nSave a copy of this notebook to your Google Drive. All changes will be saved to your own copy.\n\n\n\n\nOpen through Colab - You can use this process if you have previously saved it to your Google Drive.\n\nIn Colab, go to File>Open. This will open a dialog box.\nAt the top tabs of the dialog box, select Google Drive - you should see your previously saved copy.\n\n\n\nRun the first cell - this will connect to your Google Drive. A dialog box will open and ask you to select your Google account and ask for your permission to connect to your Google Drive.\nIt will also create a new directory in your Google Drive for all of the files needed for this project. You should see something like this indicating your new working directory.\n\nRun the cell that connects Colab to your drive. This gives permissions for information to be shared between the two and provides a safe place to store the results of your analysis.\n\nYour working directory is now set as folders on your Google Drive. All files saved here will be safe and not deleted when you close the notebook.\n\n\n\nInstall the libraries and dependencies needed for this notebook.\nThis cell also installs the spaCy model that is used to train the algorithm. There are different models as well as a wide range of language support. You can read more about them here.\n\n\n\nImport your data. Remember all those text files you created using the OCR notebook? Before running the cell in Step 3, move all your .txt files to the working directory in your Google Drive. You can drag them from your file manager (Finder in Mac, Explorer in Win) directly into the Colab file manager on the left.\n\n\n\n\nSet the number of n-grams. These are word combinations that are particular to your text. As an example, 2-grams, or bigrams, are word combinations like ‘Dalhousie University’ or ‘roller skate’. If they are separated, then contextual meaning can be lost. Whole phrases can be maintained this way, though specific phrases can be preserived at a later step.\nYou can adjust the n-grams at the code marked number_of_n=3. In this case, word combinations up to trigrams are preserved.\nAllowing unigrams (singular words) can also be permitted. However, these can dominate due to their increased frequency and should be tried to see if if improves your results. Look for the code include_unigrams=False and change False to True if you wish to include unigrams.\n\n\n\n\nStep 5 cleans the data by removing unneccesary words, punctuations, and symbols. You can also preserve certain phrases or words if they are important to you. Look for the code author_assigned_keywords =` and type each phrase or word you want inside double quotes, separating each with commas.\n\nCompleting step 5 will have created tokens and placed each documents tokens in a table along with the file name, document year, and content for further analysis.\n\n\n\nThis cell runs several processes we should be aware of.\n\nIt applies a filter against the dictionary to reduce extremes. With small corpora, we need to turn this off as you can see with the # before the line #dictionary.filter_extremes(no_below=5, no_above=0.2, keep_n=1000). If you are using a large corpus, then remove the # to make this line functional again.\nIt runs the LDA analysis with settings that can be adjusted, such as num_topics=5. In this case, 5 topics has already been specified. You can increase or decrease as you need.\n\nIt creates the pyLDAvis interactive webpage or results. This will be deposited in your working directory.\n\n\n\n\nThe final step in our process creates additional output from the analysis that may be useful for information retrieval or other analysis.\n\nThe number of topics are printed along with their score.\nThe topics and top 10 words/phrases are printed. You can cut and paste these into Excel or a table in a document for reporting.\nA Pandas table is created with the cluster and score next to each document, (since this was a document level clustering analysis). The table is exported as a .csv and saved in your working directory.\n\n\n\n\nThat is the final step in the analysis! You may want to move the filles you used for the analysis and the results into another folder if you’d like to analyze another batch. Simply move them, and put more .txt files into the working directory and you can repeat the notebook from Step 3.\nYour examples should look something like this example from a project that investigated ‘teaching effectiveness’ across a corpus of articles.\n\n\n\nThere is a testing option for evaluating the number of topics. This works best on large corpora compared with small ones. The coherence scores were a conventional way to evaluate topic analysis, but it is beginning to fall out of favor with newer methods.\nYou can read more about coherence here and here (though this is an ad-heavy website, but the explanation is helpful).\nThe graph is read as coherence closer to 0 is better.\n\n\n\n\n\nimprove the pyLDAvis to show file names as a mouseover or separate table.\nexplain more of the tuning parameters to LDA.\nEvaluate unsupervised models versus trained models"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Manateam",
    "section": "",
    "text": "To explain why, you’ll meet our three members along with our herd leader, Dr. Conrad. We’ll talk about how we got here, what we’re doing, and how we think this work is important.\n\n\n\nMaddie Hare\n\nMaddie’s academic history is just that; she graduated from Dalhousie University in 2017 and 2021 with her BA and MA in History, respectively. She is currently in her second year of the Master of Information program at Dalhousie. She hopes to continue in academia and direct her efforts at bridging disciplinary divides with digital tools!\n\nJuan Chaves Baquero\n\nJuan holds a LL.B. from Universidad de los Andes (Colombia) and is a Master of Digital Innovation student at Dalhousie University. He is writing a thesis about the readability of privacy policies, and the impacts it has on citizens’ views about e-commerce in the midst of regulation shifts in Canada.\n\nPoppy Riddle\n\nFrom the San Francisco Bay Area in California, Poppy along with her family moved to Halifax in 2020. Having graduated from Dalhousie in 2022 with a Masters in Information Management, she loved writing lit reviews so much she decided to work on a Phd spanning information science and human-computer interaction.\n\nDr. Colin Conrad\n\nDr. Conrad, (Assistant Professor of information technology in the Faculty of Management at Dalhousie University) is an interdisciplinary information technology scholar whose work draws from human-computer interaction, neuroscience, education, and data science.He is interested in how attention or other brain mechanisms impact the effectiveness of learning technologies. Recent work uses a variety of research methods borrowed from neuroscience (such as EEG and eye tracking) and information science (such as surveys and data mining) to answer research questions.\n\n\n\n\n\nThis year, we are developed tools to introduce humanities researchers to digital humanities by exploring how text-based analysis might help them develop insights. We are using machine learning to explore text found in archives from scanned documents turning them into concise topics and word exploration. We are also introducing them to two technologies that might be gateways to further exploration: the Python coding language and Tableau, a data visualization and analysis tool.\n\n\n\nDigital Humanities seeks to provide a means of synthesis for huge amounts of information, enabling researchers to explore phenomena on a scale that is impractical for manual methods. It does not seek to replace human interpretation but enable interpretation of information that is hidden due to its size, length of time, or access. Python, a widely used coding language, is great for data science and can provide a means of not only exploration but functional programs to be used by researchers. Tableau, available as both free and commercially licensed versions, provides an easy path without coding to explore massive amounts of data. We think both of these tools are a gateway for researchers to exploring electronic resources freely available or of their own creation."
  },
  {
    "objectID": "chapter-1.html",
    "href": "chapter-1.html",
    "title": "Getting started",
    "section": "",
    "text": "You will need a Google account to use the notebooks, which are on Google Colab. You can set on up Set up new Google account.\nThis does not have to be your personal account, you can set one up just for data analysis, if you like.\nIf you already have one, feel free to skip ahead to Chapter 2."
  },
  {
    "objectID": "chapter-2.html",
    "href": "chapter-2.html",
    "title": "Source material",
    "section": "",
    "text": "PDF files work best for this analysis, but there are three types of PDF files to be aware of:\n\ndigitally-created pdfs such as from print streams in Word, that contain text and font-family information, and are searchable.\nscanned/image-only pdfs that contain no text information\nsearchable pdfs - where there is a text layer that has been developed with OCR and sits underneath the scanned image\n\nArchives will typically use scanned image-only pdfs, though sometimes these are saved as PDF/A, which is a reduced file size with reduced functionality. For our Gazette project, you can find high quality scans of documents here at the Dalhousie Gazette Archives. You can find the current Gazette here.\n\nThe following is an example screenshot of a multi-page scanned image PDF file of a 1922 Dalhousie Gazette.\n\n\n\nYou can also use other source materials as you get comfortable with this process. Some examples include:\n\nimages of texts taken with your smartphone.\n\n\n\n\nThe OCR notebook we provide uses PyTesseract, which is a Python wrapper for Google’s Tesseract OCR library. It is not intended for analyzing handwritting. This article on medium.com illustrates some of the challenges. For analysis of handwriting, you will want Human Handwritten Text Recognition (HTR). For those with Python experience and time to create training datasets, you can find more here."
  },
  {
    "objectID": "chapter-3.html",
    "href": "chapter-3.html",
    "title": "The OCR notebook",
    "section": "",
    "text": "You can find the OCR notebook here on GitHub.\n\n\nAfter using the OCR notebook you will have accomplished the following:\n\n\n\nGoogle Colab is a Jupyter Notebook that runs on Google’s servers, allowing you to run Python code on data calculated and stored on cloud servers. This is great for large, computationally heavy projects where processing can be increased easily with a few lines of code. Unlike Jupyter notebooks run locally on your computer, the Colab environment is independent of your locally installed environments, meaning that you are less likely to run into conflicts. The downside to the Google Colab environment is that any information created in Colab is erased when you close the browser, unless you save it somewhere, like GitHub or locally on your computer.\n\n\n\n\n\nThere are two ways to open the OCR notebook:\n\nopen through Github [insert screenshot] - you will use this process the first time opening the notebooks.\n\nSave a copy of this notebook to your Google Drive. All changes will be saved to your own copy.\n\nOpen through Colab [insert screenshot] - You can use this process if you have previously saved it to your Google Drive.\n\nIn Colab, go to File>Open. This will open a dialog box.\nAt the top tabs of the dialog box, select Google Drive - you should see your previously saved copy.\n\n\nRun the first cell - this will connect to your Google Drive. A dialog box will open and ask you to select your Google account and ask for your permission to connect to your Google Drive.\nIt will also create a new directory in your Google Drive for all of the files needed for this project. You should see something like this indicating your new working directory.\n\nFollow the steps for 1d to put the scanned pdf files into the working directory. Colab has a file manager on the left hand side that will allow you to drag and drop files to the working directory, OCR_Project_Folder.\n\n\n\n\nInstall the dependencies and import the libraries. IF you have run this before, you may find that the runtime needs to be restarted. Its ok to do this. Just click the Restart Runtime button provided. Rerun the cell again to made sure everything has been imported.\n\n\n\nThis step gathers any and all PDF files you have placed in the working directory. What you are first starting, it is recommended that you only do one at a time, if you are working with multipage PDFs, such as those from the Gazette archives.\n\nIF you are running this analysis again, make sure you have cleaned out previous PDFs and only have the ones you want in the working directory.\nThe second cell creates the OsCaRizer function. This does all of the analysis on the PDF.\n\n\n\n\nRun this cell to take each image file and create text in a .txt file format. The output file will have the same name as the input file, but with a .txt extension.\n\n\n\n\nUnlike your own computer, Google Colab does not save anything in memory. However, since you’ve saved everything to your Google Drive, such as your results, these files will be saved indefinitely.\nThe PDF file and the output .txt files should be moved out of the working directory to a safe place, such as another Google Drive Directory. You will likely be using these in the next notebook for LDA.\nThe image files may remain as it is safe for them to be overwritten.\n\n\n\nEven for those scholars that prefer close reading, the OCR process can make reading primary texts easier as it converts scanned images into searchable text.\nAs a raw text file, there are improvements that can be made to this notebook. Improvements could be:\n\nkeep articles continuous as they are often split across pages in newspapers.\nidentify image placements with placeholder text.\ncombine with image classification methods that identify and provide context for image and text together.\nidentify other aspects of the artefact, such as damage locations or typefaces."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "",
    "text": "Welcome to our documentation introducing you to Python-based digital humanities tools."
  },
  {
    "objectID": "index.html#what-is-digital-humanities",
    "href": "index.html#what-is-digital-humanities",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "What is Digital Humanities?",
    "text": "What is Digital Humanities?\nDigital Humanities (DH) is the application of digital tools to process information to enable researchers to explore subjects in the humanities in new ways. Digital tools can provide advantages to the researcher with processing capabilities on huge amounts of information on texts, images, sound, or even on data itself. While DH employs digital technology with the goal is deriving new insights, these same tools can also be the subject of critical inquiry as well. It is a huge field with simultaneous developments in other fields. The Wikipedia entry on DH is well worth reading for an introduction, as are the resources from University of Victoria, Stanford, and the University of California Berkeley.\nOur workshop will focus on text analysis in which we look for topics, though there are many types of text analysis."
  },
  {
    "objectID": "index.html#this-documentation-covers-the-following",
    "href": "index.html#this-documentation-covers-the-following",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "This documentation covers the following:",
    "text": "This documentation covers the following:\n\nChapter 1 - Getting started\nChapter 2 - Finding source material\nChapter 3 - Using the OCR notebook\nChapter 4 - Using the LDA notebook\nChapter 5 - Moving on and using your own data"
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "Objectives",
    "text": "Objectives\nOur workshop seeks to provide the following for our participants: \n\nUse Python to run an Optical Character Recognition (OCR) library called PyTesseract to extract text from a scanned PDF file and perform topic modeling using LDA to derive meaningful topics.\nCreate visualizations, with both Python and Tableau Public, to generate meaningful topics from the text.\nDescribe basic elements of Python, Google Colab and Tableau Public.\nCover the basics of Jupyter Notebooks hosted in the Google Colab environment.\nExplore the basic principles and limitations of topic modeling.\nDiscuss open source software and publicly available information can be implemented in social sciences and humanities research.\nUse Tableau Public to explore and analyze data using no coding, but able to produce visualizations and tables.\nCover the process to create topics from a sample covering 100 years of the Dalhousie Gazette."
  },
  {
    "objectID": "index.html#what-is-ocr",
    "href": "index.html#what-is-ocr",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "What is OCR?",
    "text": "What is OCR?\n\nOCR is Optical Character Recognition is a means of converting scanned or an image of text into searchable text that can be used for analysis. OCR has wide applications in text-to-speech, text mining and natural language processing, translation, and computer vision.\nOCR has a long history as far back as the early 1900’s, when text was optically converted into tones as an assistive technology. Today, mobile applications come with every smartphone enabling translation of signs across many languages. Google Books and Project Gutenberg are other examples of scanned image to text OCR processing.\nOur version of OCR is a Python wrapper for Google’s Tesseract which has advantages on unusual fonts or poor quality scans.\nThe input for our Python library, Pytesseract, uses PDF files. There are three types of PDF files:\n\ndigitally-created pdfs such as from print streams in Word, that contain text and font-family information, and are searchable.\nscanned/image-only pdfs that contain no text information\nsearchable pdfs - where there is a text layer that has been developed with OCR and sits underneath the scanned image\n\nAs there can be challenges with pdfs, Pytesseract will first convert all of them to images regardless of their type, process the characters using neural networks, and output the files as a plain text stream. We will then use the text files for further analysis using LDA topic modeling."
  },
  {
    "objectID": "index.html#what-is-lda",
    "href": "index.html#what-is-lda",
    "title": "Manateam Documentation on OCR and LDA",
    "section": "What is LDA?",
    "text": "What is LDA?\n\nLDA, Latent Dirichlet Allocation, is a probability-based natural language processing (NLP) algorithm, that is specifically used to identify unknown topics within a text. While not the current state of the art, it is robust and still works pretty well!\nOur LDA notebook uses the Gensim LDA model which establishes document similarity. You can see the Gensim documentation here.\nLDA is one of a growing number of topic modelling methods used for information retrieval, enabling linked data and semantic web searching. For digital humanities researchers, we can identify topics across groups of documents, or establish document similarity, though it still relies upon the expertise of the observer to interpret ambiguous or contextual specific terms.\nWhile the notebook does have a coherence test included for validating the chosen number of topics, DH researchers should still rely upon manually validating the results.\n\nReady? Move on to Chapter 2, Getting Started."
  }
]